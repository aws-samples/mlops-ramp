{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327dd0be-8ba8-43e5-b178-eb1db8d3d40a",
   "metadata": {},
   "source": [
    "# <B> Training </B>\n",
    "* Container: codna_pytorch_p39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecd494-5ac0-4f66-a3cc-340e847e3c46",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07a9ee3-c178-41b6-a212-2a33f65dc377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc9dda-9dad-4f81-8dd5-53b5623f1d93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. parameter store 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6e737a-557b-44c7-a5c2-f6798bf0c430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from utils.ssm import parameter_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9894a8-4249-4fcc-9b44-d5f43f4fd867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strRegionName=boto3.Session().region_name\n",
    "pm = parameter_store(strRegionName)\n",
    "prefix = pm.get_params(key=\"PREFIX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0674243-6019-4e5e-8563-2fd17ca8ae95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.Training-job for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68c1bf7-336d-46b9-940e-9e5b570e1793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from omegaconf import OmegaConf\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FrameworkProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9bb6a-d48d-46f7-bb83-a47255503b6f",
   "metadata": {},
   "source": [
    "* **Set Up SageMaker Experiment**\n",
    "    - Create or load [SageMaker Experiment](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) for the example training job. This will create an experiment trial object in SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9612750e-acc9-418c-be4f-24ce6a79726b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6a12e2b-2456-4419-8c75-e95d2ca6eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489351d8-9d95-4483-af38-0bd3f9c80add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_trial(experiment_name):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c8e85-ea66-4fbd-bdde-551400b0f872",
   "metadata": {
    "tags": []
   },
   "source": [
    "* **Configure the training job**\n",
    "\n",
    "    - Now we configure the training job, by modifying the `config.yaml` file that is stored in our source code directory.\n",
    "    - We pass relative directory paths for the data based on the SageMaker mount directory on the remote instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bcde0a-bcde-4ad3-a0dc-7b844ac1b733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_dir = \"./code\"\n",
    "config_dir = \"./code/conf\"\n",
    "config_path = os.path.join(config_dir, \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3076c-bfae-4589-963a-4f1288761e62",
   "metadata": {},
   "source": [
    "* params for training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7460084-c1f4-472d-909c-ce723634b26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = False\n",
    "\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local_gpu\"\n",
    "    \n",
    "    from sagemaker.local import LocalSession\n",
    "    import os\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    \n",
    "    local_data_dir = os.getcwd() + '/data/preprocessing'\n",
    "    pretrained = os.getcwd() + '/pretrained/CTC.nemo'\n",
    "    \n",
    "    data_channels = {\"training\": f\"file://{local_data_dir}\", \"testing\": f\"file://{local_data_dir}\", \"pretrained\": f\"file://{pretrained}\"}\n",
    "    \n",
    "else:\n",
    "    \n",
    "    instance_type = \"ml.g4dn.8xlarge\" #\"ml.p3.2xlarge\"#\"ml.g4dn.8xlarge\"#\"ml.p3.2xlarge\", 'ml.p3.16xlarge' , ml.g4dn.8xlarge\n",
    "    \n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    data_channels = {\"training\": pm.get_params(key=\"-\".join([prefix, \"PREP-DATA-PATH\"])), \n",
    "                     \"testing\": pm.get_params(key=\"-\".join([prefix, \"PREP-DATA-PATH\"])), \n",
    "                     \"pretrained\": pm.get_params(key=prefix + \"-PRETRAINED-WEIGHT\")}\n",
    "\n",
    "instance_count = 1\n",
    "do_spot_training = False\n",
    "max_wait = None\n",
    "max_run = 1*60*60   \n",
    "\n",
    "resume = True\n",
    "    \n",
    "proc_prefix = \"/opt/ml/processing\"\n",
    "bucket_name = pm.get_params(key=prefix + \"-BUCKET\")\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"training\",\n",
    "    \"model-output\"\n",
    ")\n",
    "\n",
    "code_location = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"training\",\n",
    "    \"backup_codes\"\n",
    ")\n",
    "\n",
    "experiment_name = '-'.join([prefix, \"nemo-experiments\"])\n",
    "\n",
    "num_re = \"([0-9\\\\.]+)(e-?[[01][0-9])?\"\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"train_loss\", \"Regex\": f\"loss={num_re}\"},\n",
    "    {\"Name\": \"wer\", \"Regex\": f\"wer:{num_re}\"}\n",
    "]\n",
    "\n",
    "git_config = {\n",
    "    'repo': f'https://{pm.get_params(key=\"-\".join([prefix, \"CODE_REPO\"]))}',\n",
    "    'branch': 'main',\n",
    "    'username': pm.get_params(key=\"-\".join([prefix, \"CODECOMMIT-USERNAME\"]), enc=True),\n",
    "    'password': pm.get_params(key=\"-\".join([prefix, \"CODECOMMIT-PWD\"]), enc=True)\n",
    "}  \n",
    "\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26003edf-356a-4e1d-82b1-c8085b508b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_name : nemo-asr-nemo-experiments \n",
      "train_instance_type : ml.g4dn.8xlarge \n",
      "train_instance_count : 1\n",
      "data_channels : {'training': 's3://sm-nemo-ramp/nemo-asr/preprocessing/data', 'testing': 's3://sm-nemo-ramp/nemo-asr/preprocessing/data', 'pretrained': 's3://sm-nemo-ramp/nemo-asr/pretrained'}\n",
      "experiment_name : nemo-asr-nemo-experiments\n",
      " git_config : {'repo': 'https://git-codecommit.us-east-1.amazonaws.com/v1/repos/nemo-code', 'branch': 'main', 'username': 'dongjin-at-419974056037', 'password': 'wtLv/fP4ESjBDnyW5xgqFPGR0dMTIyK5/8gK6IS1Zsg='}\n"
     ]
    }
   ],
   "source": [
    "print(\"experiment_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {}\\ndata_channels : {}\\nexperiment_name : {}\\n git_config : {}\".format(experiment_name, instance_type, instance_count, data_channels, experiment_name, git_config))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51e768-c740-42c6-9a74-c09a1b337405",
   "metadata": {},
   "source": [
    "* config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b07e1646-aa7f-49e7-996a-d7cbf22e26c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(config_path)\n",
    "\n",
    "# Sampling\n",
    "conf.model.sample_rate = 16000\n",
    "\n",
    "# Set Data Locations based on the mounted directory in the SageMaker instance\n",
    "conf.model.train_ds.manifest_filepath = \"/opt/ml/input/data/training/an4/train_manifest.json\"\n",
    "conf.model.validation_ds.manifest_filepath = \"/opt/ml/input/data/testing/an4/test_manifest.json\"\n",
    "# training setup\n",
    "conf.trainer.accelerator = \"gpu\"\n",
    "conf.trainer.num_nodes = instance_count\n",
    "# enable SageMaker DDP\n",
    "conf.trainer.strategy = None #\"ddp\"\n",
    "conf.trainer.max_epochs = 2\n",
    "\n",
    "# Output directory for our experiment within the SageMaker instance\n",
    "conf.exp_manager.exp_dir=\"/opt/ml/model/\"\n",
    "\n",
    "# Create a Small Variant of the Conformer Model\n",
    "conf.model.encoder.n_layers = 8\n",
    "conf.model.n_heads = 4\n",
    "conf.model.spec_augment.time_masks = 5\n",
    "\n",
    "# Set Optimizer parameters\n",
    "conf.model.optim.lr = 2.0 # by default we using Noam scheduling, the LR is a multiplier\n",
    "\n",
    "if resume == False:\n",
    "    # resume flags if crashes occur\n",
    "    conf.exp_manager.resume_if_exists=False \n",
    "    conf.exp_manager.resume_ignore_no_checkpoint=False\n",
    "    conf.init_from_nemo_model = None\n",
    "    \n",
    "else:\n",
    "    # resume flags if crashes occur\n",
    "    conf.exp_manager.resume_if_exists=True\n",
    "    conf.exp_manager.resume_ignore_no_checkpoint=True\n",
    "    # the pre-trained model we want to fine-tune\n",
    "    conf.init_from_nemo_model = \"/opt/ml/input/data/pretrained/CTC.nemo\"\n",
    "    \n",
    "\n",
    "OmegaConf.save(conf, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604a35c-4057-4a4f-b308-640a9cc54277",
   "metadata": {},
   "source": [
    "* Define processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b054583-4b34-4e4f-bd37-a15a11df6add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('419974056037.dkr.ecr.us-east-1.amazonaws.com/nemo-test-training', './code')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.get_params(key=''.join([prefix, \"-IMAGE-URI\"])), code_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1576ea06-1ac4-4e11-8106-671a3f88cc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "est = PyTorch(\n",
    "    entry_point=\"speech_to_text_ctc.py\", # the script we want to run\n",
    "    source_dir=code_dir, # where our conf/script is\n",
    "    git_config=git_config,\n",
    "    role=pm.get_params(key=prefix + \"-SAGEMAKER-ROLE-ARN\"),\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    image_uri=pm.get_params(key=''.join([prefix, \"-IMAGE-URI\"])),\n",
    "    # framework_version=\"1.13.1\", # version of PyTorch\n",
    "    # py_version=\"py39\",\n",
    "    volume_size=256,\n",
    "    code_location = code_location,\n",
    "    output_path=output_path,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters={'config-path': 'conf'},\n",
    "    #distribution={\"smdistributed\":{\"dataparallel\":{\"enabled\":True, \"fp16\": True}}},\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_run=max_run,\n",
    "    enable_sagemaker_metrics=True,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883bc2a-69e5-436d-aef3-67e994c1f553",
   "metadata": {},
   "source": [
    "* run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8640b12b-761f-4fbd-9f09-cac4b2709d2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "Cloning into '/tmp/tmplptyic8i'...\n",
      "remote: Counting objects: 20, done.        \n",
      "Already on 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: nemo-asr-nemo-experiments-0322-10521679482352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:52:46 Starting - Starting the training job...\n",
      "2023-03-22 10:53:00 Starting - Preparing the instances for training......\n",
      "2023-03-22 10:54:01 Downloading - Downloading input data...\n",
      "2023-03-22 10:54:26 Training - Downloading the training image..................\n",
      "2023-03-22 10:57:53 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,669 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,689 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,700 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,702 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,950 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:35,981 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:36,014 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:36,025 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"pretrained\": \"/opt/ml/input/data/pretrained\",\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.8xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config-path\": \"conf\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"pretrained\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"nemo-asr-nemo-experiments-0322-10521679482352\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sm-nemo-ramp/nemo-asr/training/backup_codes/nemo-asr-nemo-experiments-0322-10521679482352/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"speech_to_text_ctc\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"speech_to_text_ctc.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config-path\":\"conf\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=speech_to_text_ctc.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"pretrained\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"pretrained\",\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.8xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=speech_to_text_ctc\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sm-nemo-ramp/nemo-asr/training/backup_codes/nemo-asr-nemo-experiments-0322-10521679482352/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"pretrained\":\"/opt/ml/input/data/pretrained\",\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.8xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config-path\":\"conf\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pretrained\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"nemo-asr-nemo-experiments-0322-10521679482352\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sm-nemo-ramp/nemo-asr/training/backup_codes/nemo-asr-nemo-experiments-0322-10521679482352/source/sourcedir.tar.gz\",\"module_name\":\"speech_to_text_ctc\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"speech_to_text_ctc.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config-path\",\"conf\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_PRETRAINED=/opt/ml/input/data/pretrained\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG-PATH=conf\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 speech_to_text_ctc.py --config-path conf\u001b[0m\n",
      "\u001b[34m[2023-03-22 10:58:37.863: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.0.dev0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:37,867 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-03-22 10:58:37,892 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mos.environ: environ({'SM_INPUT_DIR': '/opt/ml/input', 'PYTHONIOENCODING': 'UTF-8', 'NV_CUDA_COMPAT_PACKAGE': 'cuda-compat-11-7', 'NCCL_DEBUG': 'WARN', 'HOROVOD_VERSION': '0.26.1', 'NCCL_SOCKET_IFNAME': 'eth0', 'SM_USER_ENTRY_POINT': 'speech_to_text_ctc.py', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"}', 'SM_CURRENT_INSTANCE_TYPE': 'ml.g4dn.8xlarge', 'EFA_VERSION': '1.19.0', 'MASTER_ADDR': 'algo-1', 'SM_MODULE_NAME': 'speech_to_text_ctc', 'HOSTNAME': 'ip-10-0-239-63.ec2.internal', 'CURRENT_HOST': 'algo-1', 'SHLVL': '1', 'LD_LIBRARY_PATH': '/opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib', 'HOME': '/root', 'MASTER_PORT': '7777', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'TORCH_NVCC_FLAGS': '-Xfatbin -compress-all', 'SM_INPUT_DATA_CONFIG': '{\"pretrained\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'PYTHONUNBUFFERED': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:419974056037:training-job/nemo-asr-nemo-experiments-0322-10521679482352', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_CHANNEL_PRETRAINED': '/opt/ml/input/data/pretrained', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'BRANCH_OFI': '1.4.0-aws', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-e24ade0e40e151b375ae86becc87641e62d7bc0e4fbb008e3c134b778c23c7db-customer', 'SM_FRAMEWORK_MODULE': 'sagemaker_pytorch_container.training:main', 'SM_NUM_CPUS': '32', 'CUDA_VERSION': '11.7.1', 'TORCH_CUDA_ARCH_LIST': '3.7 5.0 7.0+PTX 8.0', 'SM_NUM_GPUS': '1', 'PYTHONDONTWRITEBYTECODE': '1', 'SM_NUM_NEURONS': '0', 'SM_MODULE_DIR': 's3://sm-nemo-ramp/nemo-asr/training/backup_codes/nemo-asr-nemo-experiments-0322-10521679482352/source/sourcedir.tar.gz', 'NVIDIA_REQUIRE_CUDA': 'cuda>=11.7 brand=tesla,driver>=450,driver<451 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=510,driver<511 brand=unknown,driver>=510,driver<511 brand=nvidia,driver>=510,driver<511 brand=nvidiartx,driver>=510,driver<511 brand=geforce,driver>=510,driver<511 brand=geforcertx,driver>=510,driver<511 brand=quadro,driver>=510,driver<511 brand=quadrortx,driver>=510,driver<511 brand=titan,driver>=510,driver<511 brand=titanrtx,driver>=510,driver<511', 'RDMAV_FORK_SAFE': '1', '_': '/opt/conda/bin/train', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility,compat32,graphics,video', 'SM_LOG_LEVEL': '20', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'NV_CUDA_CUDART_VERSION': '11.7.99-1', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"pretrained\":\"/opt/ml/input/data/pretrained\",\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.8xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config-path\":\"conf\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pretrained\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"nemo-asr-nemo-experiments-0322-10521679482352\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sm-nemo-ramp/nemo-asr/training/backup_codes/nemo-asr-nemo-experiments-0322-10521679482352/source/sourcedir.tar.gz\",\"module_name\":\"speech_to_text_ctc\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"speech_to_text_ctc.py\"}', 'PATH': '/opt/amazon/openmpi/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'NVARCH': 'x86_64', 'REQUESTS_CA_BUNDLE': '/etc/ssl/certs/ca-certificates.crt', 'DMLC_INTERFACE': 'eth0', 'SM_INSTANCE_GROUPS_DICT': '{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.8xlarge\"}}', 'LD_PRELOAD': '/libchangehostname.so', 'LANG': 'C.UTF-8', 'SM_HPS': '{\"config-path\":\"conf\"}', 'NCCL_IB_DISABLE': '1', 'SM_INSTANCE_GROUPS': '[\"homogeneousCluster\"]', 'CUDNN_VERSION': '8.5.0.96', 'DEBIAN_FRONTEND': 'noninteractive', 'SM_CHANNELS': '[\"pretrained\",\"testing\",\"training\"]', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[\"algo-1\"]', 'SM_IS_HETERO': 'false', 'AWS_REGION': 'us-east-1', 'OPEN_MPI_PATH': '/opt/amazon/openmpi', 'DLC_CONTAINER_TYPE': 'training', 'SAGEMAKER_JOB_NAME': 'nemo-asr-nemo-experiments-0322-10521679482352', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'PWD': '/opt/ml/code', 'TRAINING_JOB_NAME': 'nemo-asr-nemo-experiments-0322-10521679482352', 'LC_ALL': 'C.UTF-8', 'SAGEMAKER_TRAINING_MODULE': 'sagemaker_pytorch_container.training:main', 'OMPI_VERSION': '4.1.1', 'SM_HOSTS': '[\"algo-1\"]', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[]', 'SM_CHANNEL_TESTING': '/opt/ml/input/data/testing', 'MANUAL_BUILD': '0', 'SAGEMAKER_REGION': 'us-east-1', 'PYTHONPATH': '/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages', 'NVIDIA_VISIBLE_DEVICES': 'all', 'NCCL_VERSION': '2.14.3', 'DGLBACKEND': 'pytorch', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_USER_ARGS': '[\"--config-path\",\"conf\"]', 'CMAKE_PREFIX_PATH': '$(dirname $(which conda))/../', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster'})\u001b[0m\n",
      "\u001b[34mHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\u001b[0m\n",
      "\u001b[34mGet:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\u001b[0m\n",
      "\u001b[34mGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\u001b[0m\n",
      "\u001b[34mGet:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\u001b[0m\n",
      "\u001b[34mGet:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3026 kB]\u001b[0m\n",
      "\u001b[34mFetched 3362 kB in 1s (5656 kB/s)\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mReading package lists...\u001b[0m\n",
      "\u001b[34mBuilding dependency tree...\u001b[0m\n",
      "\u001b[34mReading state information...\u001b[0m\n",
      "\u001b[34mlibsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\u001b[0m\n",
      "\u001b[34mlibsndfile1 set to manually installed.\u001b[0m\n",
      "\u001b[34mThe following additional packages will be installed:\u001b[0m\n",
      "\u001b[34mi965-va-driver intel-media-va-driver libaacs0 libaom0 libass9 libavc1394-0\n",
      "  libavcodec58 libavdevice58 libavfilter7 libavformat58 libavresample4\u001b[0m\n",
      "\u001b[34mlibavutil56 libbdplus0 libbluray2 libbs2b0 libcaca0 libcdio-cdda2\n",
      "  libcdio-paranoia2 libcdio18 libchromaprint1 libcodec2-0.9 libdc1394-22\n",
      "  libflite1 libgme0 libiec61883-0 libigdgmm11 libjack-jackd2-0 liblilv-0-0\n",
      "  libmpg123-0 libmysofa1 libnorm1 libopenal-data libopenal1 libopenjp2-7\u001b[0m\n",
      "\u001b[34mlibopenmpt0 libopus0 libpgm-5.2-0 libpostproc55 libraw1394-11 librubberband2\n",
      "  libsamplerate0 libsdl2-2.0-0 libserd-0-0 libshine3 libslang2 libsnappy1v5\n",
      "  libsndio7.0 libsodium23 libsord-0-0 libsoxr0 libspeex1 libsratom-0-0\n",
      "  libssh-gcrypt-4 libswresample3 libswscale5 libtheora0 libusb-1.0-0\n",
      "  libva-drm2 libva-x11-2 libva2 libvdpau1 libvidstab1.1 libvpx6 libx264-155\n",
      "  libx265-179 libxcb-shape0 libxss1 libxv1 libxvidcore4 libzmq5 libzvbi-common\u001b[0m\n",
      "\u001b[34mlibzvbi0 mesa-va-drivers mesa-vdpau-drivers ocl-icd-libopencl1 va-driver-all\n",
      "  vdpau-driver-all\u001b[0m\n",
      "\u001b[34mSuggested packages:\n",
      "  ffmpeg-doc i965-va-driver-shaders libbluray-bdj jackd2 libportaudio2\n",
      "  opus-tools libraw1394-doc serdi sndiod sordi speex opencl-icd\n",
      "  libvdpau-va-gl1 nvidia-vdpau-driver nvidia-legacy-340xx-vdpau-driver\n",
      "  nvidia-legacy-304xx-vdpau-driver\u001b[0m\n",
      "\u001b[34mThe following NEW packages will be installed:\u001b[0m\n",
      "\u001b[34mffmpeg i965-va-driver intel-media-va-driver libaacs0 libaom0 libass9\n",
      "  libavc1394-0 libavcodec58 libavdevice58 libavfilter7 libavformat58\u001b[0m\n",
      "\u001b[34mlibavresample4 libavutil56 libbdplus0 libbluray2 libbs2b0 libcaca0\n",
      "  libcdio-cdda2 libcdio-paranoia2 libcdio18 libchromaprint1 libcodec2-0.9\u001b[0m\n",
      "\u001b[34mlibdc1394-22 libflite1 libgme0 libiec61883-0 libigdgmm11 libjack-jackd2-0\u001b[0m\n",
      "\u001b[34mliblilv-0-0 libmpg123-0 libmysofa1 libnorm1 libopenal-data libopenal1\u001b[0m\n",
      "\u001b[34mlibopenjp2-7 libopenmpt0 libopus0 libpgm-5.2-0 libpostproc55 libraw1394-11\u001b[0m\n",
      "\u001b[34mlibrubberband2 libsamplerate0 libsdl2-2.0-0 libserd-0-0 libshine3 libslang2\n",
      "  libsnappy1v5 libsndio7.0 libsodium23 libsord-0-0 libsoxr0 libspeex1\u001b[0m\n",
      "\u001b[34mlibsratom-0-0 libssh-gcrypt-4 libswresample3 libswscale5 libtheora0\n",
      "  libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1 libvidstab1.1 libvpx6\n",
      "  libx264-155 libx265-179 libxcb-shape0 libxss1 libxv1 libxvidcore4 libzmq5\u001b[0m\n",
      "\u001b[34mlibzvbi-common libzvbi0 mesa-va-drivers mesa-vdpau-drivers\u001b[0m\n",
      "\u001b[34mocl-icd-libopencl1 va-driver-all vdpau-driver-all\u001b[0m\n",
      "\u001b[34m0 upgraded, 78 newly installed, 0 to remove and 37 not upgraded.\u001b[0m\n",
      "\u001b[34mNeed to get 49.2 MB of archives.\u001b[0m\n",
      "\u001b[34mAfter this operation, 218 MB of additional disk space will be used.\u001b[0m\n",
      "\u001b[34mGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libslang2 amd64 2.3.2-4 [429 kB]\u001b[0m\n",
      "\u001b[34mGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libsodium23 amd64 1.0.18-1 [150 kB]\u001b[0m\n",
      "\u001b[34mGet:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libusb-1.0-0 amd64 2:1.0.23-2build1 [46.5 kB]\u001b[0m\n",
      "\u001b[34mGet:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaom0 amd64 1.0.0.errata1-3build1 [1160 kB]\u001b[0m\n",
      "\u001b[34mGet:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva2 amd64 2.7.0-2 [53.5 kB]\u001b[0m\n",
      "\u001b[34mGet:6 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva-drm2 amd64 2.7.0-2 [7044 B]\u001b[0m\n",
      "\u001b[34mGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva-x11-2 amd64 2.7.0-2 [11.9 kB]\u001b[0m\n",
      "\u001b[34mGet:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libvdpau1 amd64 1.3-1ubuntu2 [25.6 kB]\u001b[0m\n",
      "\u001b[34mGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 ocl-icd-libopencl1 amd64 2.2.11-1ubuntu1 [30.3 kB]\u001b[0m\n",
      "\u001b[34mGet:10 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavutil56 amd64 7:4.2.7-0ubuntu0.1 [241 kB]\u001b[0m\n",
      "\u001b[34mGet:11 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcodec2-0.9 amd64 0.9.2-2 [7886 kB]\u001b[0m\n",
      "\u001b[34mGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libopenjp2-7 amd64 2.3.1-1ubuntu4.20.04.1 [141 kB]\u001b[0m\n",
      "\u001b[34mGet:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libopus0 amd64 1.3.1-0ubuntu1 [191 kB]\u001b[0m\n",
      "\u001b[34mGet:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 libshine3 amd64 3.1.1-2 [23.2 kB]\u001b[0m\n",
      "\u001b[34mGet:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libsnappy1v5 amd64 1.1.8-1build1 [16.7 kB]\u001b[0m\n",
      "\u001b[34mGet:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libspeex1 amd64 1.2~rc1.2-1.1ubuntu1.20.04.1 [53.2 kB]\u001b[0m\n",
      "\u001b[34mGet:17 http://archive.ubuntu.com/ubuntu focal/main amd64 libsoxr0 amd64 0.1.3-2build1 [78.0 kB]\u001b[0m\n",
      "\u001b[34mGet:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libswresample3 amd64 7:4.2.7-0ubuntu0.1 [57.1 kB]\u001b[0m\n",
      "\u001b[34mGet:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libtheora0 amd64 1.1.1+dfsg.1-15ubuntu2 [162 kB]\u001b[0m\n",
      "\u001b[34mGet:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libvpx6 amd64 1.8.2-1build1 [820 kB]\u001b[0m\n",
      "\u001b[34mGet:21 http://archive.ubuntu.com/ubuntu focal/universe amd64 libx264-155 amd64 2:0.155.2917+git0a84d98-2 [521 kB]\u001b[0m\n",
      "\u001b[34mGet:22 http://archive.ubuntu.com/ubuntu focal/universe amd64 libx265-179 amd64 3.2.1-1build1 [1060 kB]\u001b[0m\n",
      "\u001b[34mGet:23 http://archive.ubuntu.com/ubuntu focal/universe amd64 libxvidcore4 amd64 2:1.3.7-1 [201 kB]\u001b[0m\n",
      "\u001b[34mGet:24 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzvbi-common all 0.2.35-17 [32.5 kB]\u001b[0m\n",
      "\u001b[34mGet:25 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzvbi0 amd64 0.2.35-17 [237 kB]\u001b[0m\n",
      "\u001b[34mGet:26 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavcodec58 amd64 7:4.2.7-0ubuntu0.1 [4878 kB]\u001b[0m\n",
      "\u001b[34mGet:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libraw1394-11 amd64 2.1.2-1 [30.7 kB]\u001b[0m\n",
      "\u001b[34mGet:28 http://archive.ubuntu.com/ubuntu focal/main amd64 libavc1394-0 amd64 0.5.4-5 [16.2 kB]\u001b[0m\n",
      "\u001b[34mGet:29 http://archive.ubuntu.com/ubuntu focal/universe amd64 libass9 amd64 1:0.14.0-2 [88.0 kB]\u001b[0m\n",
      "\u001b[34mGet:30 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbluray2 amd64 1:1.2.0-1 [138 kB]\u001b[0m\n",
      "\u001b[34mGet:31 http://archive.ubuntu.com/ubuntu focal/universe amd64 libchromaprint1 amd64 1.4.3-3build1 [37.6 kB]\u001b[0m\n",
      "\u001b[34mGet:32 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgme0 amd64 0.6.2-1build1 [123 kB]\u001b[0m\n",
      "\u001b[34mGet:33 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpg123-0 amd64 1.25.13-1 [124 kB]\u001b[0m\n",
      "\u001b[34mGet:34 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenmpt0 amd64 0.4.11-1build1 [599 kB]\u001b[0m\n",
      "\u001b[34mGet:35 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libssh-gcrypt-4 amd64 0.9.3-2ubuntu2.2 [202 kB]\u001b[0m\n",
      "\u001b[34mGet:36 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavformat58 amd64 7:4.2.7-0ubuntu0.1 [985 kB]\u001b[0m\n",
      "\u001b[34mGet:37 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbs2b0 amd64 3.1.0+dfsg-2.2build1 [10.2 kB]\u001b[0m\n",
      "\u001b[34mGet:38 http://archive.ubuntu.com/ubuntu focal/universe amd64 libflite1 amd64 2.1-release-3 [12.8 MB]\u001b[0m\n",
      "\u001b[34mGet:39 http://archive.ubuntu.com/ubuntu focal/universe amd64 libserd-0-0 amd64 0.30.2-1 [46.6 kB]\u001b[0m\n",
      "\u001b[34mGet:40 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsord-0-0 amd64 0.16.4-1 [19.5 kB]\u001b[0m\n",
      "\u001b[34mGet:41 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsratom-0-0 amd64 0.6.4-1 [16.9 kB]\u001b[0m\n",
      "\u001b[34mGet:42 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 liblilv-0-0 amd64 0.24.6-1ubuntu0.1 [40.6 kB]\u001b[0m\n",
      "\u001b[34mGet:43 http://archive.ubuntu.com/ubuntu focal/universe amd64 libmysofa1 amd64 1.0~dfsg0-1 [39.2 kB]\u001b[0m\n",
      "\u001b[34mGet:44 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpostproc55 amd64 7:4.2.7-0ubuntu0.1 [55.0 kB]\u001b[0m\n",
      "\u001b[34mGet:45 http://archive.ubuntu.com/ubuntu focal/main amd64 libsamplerate0 amd64 0.1.9-2 [939 kB]\u001b[0m\n",
      "\u001b[34mGet:46 http://archive.ubuntu.com/ubuntu focal/universe amd64 librubberband2 amd64 1.8.2-1build1 [89.4 kB]\u001b[0m\n",
      "\u001b[34mGet:47 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libswscale5 amd64 7:4.2.7-0ubuntu0.1 [157 kB]\u001b[0m\n",
      "\u001b[34mGet:48 http://archive.ubuntu.com/ubuntu focal/universe amd64 libvidstab1.1 amd64 1.1.0-2 [35.0 kB]\u001b[0m\n",
      "\u001b[34mGet:49 http://archive.ubuntu.com/ubuntu focal/universe amd64 libnorm1 amd64 1.5.8+dfsg2-2build1 [290 kB]\u001b[0m\n",
      "\u001b[34mGet:50 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpgm-5.2-0 amd64 5.2.122~dfsg-3ubuntu1 [158 kB]\u001b[0m\n",
      "\u001b[34mGet:51 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzmq5 amd64 4.3.2-2ubuntu1 [242 kB]\u001b[0m\n",
      "\u001b[34mGet:52 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavfilter7 amd64 7:4.2.7-0ubuntu0.1 [1085 kB]\u001b[0m\n",
      "\u001b[34mGet:53 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcaca0 amd64 0.99.beta19-2.1ubuntu1.20.04.2 [203 kB]\u001b[0m\n",
      "\u001b[34mGet:54 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio18 amd64 2.0.0-2 [58.6 kB]\u001b[0m\n",
      "\u001b[34mGet:55 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-cdda2 amd64 10.2+2.0.0-1 [17.6 kB]\u001b[0m\n",
      "\u001b[34mGet:56 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-paranoia2 amd64 10.2+2.0.0-1 [16.2 kB]\u001b[0m\n",
      "\u001b[34mGet:57 http://archive.ubuntu.com/ubuntu focal/universe amd64 libdc1394-22 amd64 2.2.5-2.1 [79.6 kB]\u001b[0m\n",
      "\u001b[34mGet:58 http://archive.ubuntu.com/ubuntu focal/main amd64 libiec61883-0 amd64 1.2.0-3 [24.3 kB]\u001b[0m\n",
      "\u001b[34mGet:59 http://archive.ubuntu.com/ubuntu focal/main amd64 libjack-jackd2-0 amd64 1.9.12~dfsg-2ubuntu2 [267 kB]\u001b[0m\n",
      "\u001b[34mGet:60 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal-data all 1:1.19.1-1 [162 kB]\u001b[0m\n",
      "\u001b[34mGet:61 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsndio7.0 amd64 1.5.0-3 [24.5 kB]\u001b[0m\n",
      "\u001b[34mGet:62 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal1 amd64 1:1.19.1-1 [492 kB]\u001b[0m\n",
      "\u001b[34mGet:63 http://archive.ubuntu.com/ubuntu focal/main amd64 libxss1 amd64 1:1.2.3-1 [8140 B]\u001b[0m\n",
      "\u001b[34mGet:64 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsdl2-2.0-0 amd64 2.0.10+dfsg1-3 [407 kB]\u001b[0m\n",
      "\u001b[34mGet:65 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shape0 amd64 1.14-2 [5928 B]\u001b[0m\n",
      "\u001b[34mGet:66 http://archive.ubuntu.com/ubuntu focal/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\u001b[0m\n",
      "\u001b[34mGet:67 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavdevice58 amd64 7:4.2.7-0ubuntu0.1 [74.3 kB]\u001b[0m\n",
      "\u001b[34mGet:68 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavresample4 amd64 7:4.2.7-0ubuntu0.1 [54.2 kB]\u001b[0m\n",
      "\u001b[34mGet:69 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 ffmpeg amd64 7:4.2.7-0ubuntu0.1 [1453 kB]\u001b[0m\n",
      "\u001b[34mGet:70 http://archive.ubuntu.com/ubuntu focal/universe amd64 libigdgmm11 amd64 20.1.1+ds1-1 [111 kB]\u001b[0m\n",
      "\u001b[34mGet:71 http://archive.ubuntu.com/ubuntu focal/universe amd64 intel-media-va-driver amd64 20.1.1+dfsg1-1 [1764 kB]\u001b[0m\n",
      "\u001b[34mGet:72 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaacs0 amd64 0.9.0-2 [50.1 kB]\u001b[0m\n",
      "\u001b[34mGet:73 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbdplus0 amd64 0.1.2-3 [47.3 kB]\u001b[0m\n",
      "\u001b[34mGet:74 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 mesa-va-drivers amd64 21.2.6-0ubuntu0.1~20.04.2 [2970 kB]\u001b[0m\n",
      "\u001b[34mGet:75 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 mesa-vdpau-drivers amd64 21.2.6-0ubuntu0.1~20.04.2 [3089 kB]\u001b[0m\n",
      "\u001b[34mGet:76 http://archive.ubuntu.com/ubuntu focal/universe amd64 i965-va-driver amd64 2.4.0-0ubuntu1 [924 kB]\u001b[0m\n",
      "\u001b[34mGet:77 http://archive.ubuntu.com/ubuntu focal/universe amd64 va-driver-all amd64 2.7.0-2 [4020 B]\u001b[0m\n",
      "\u001b[34mGet:78 http://archive.ubuntu.com/ubuntu focal/main amd64 vdpau-driver-all amd64 1.3-1ubuntu2 [4596 B]\u001b[0m\n",
      "\u001b[34mdebconf: delaying package configuration, since apt-utils is not installed\u001b[0m\n",
      "\u001b[34mFetched 49.2 MB in 1s (38.3 MB/s)\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libslang2:amd64.#015\u001b[0m\n",
      "\u001b[34m(Reading database ...\u001b[0m\n",
      "\u001b[34m(Reading database ... 5%#015(Reading database ... 10%#015(Reading database ... 15%#015(Reading database ... 20%#015(Reading database ... 25%#015(Reading database ... 30%#015(Reading database ... 35%\u001b[0m\n",
      "\u001b[34m(Reading database ... 40%#015(Reading database ... 45%#015(Reading database ... 50%#015(Reading database ... 55%\u001b[0m\n",
      "\u001b[34m(Reading database ... 60%\u001b[0m\n",
      "\u001b[34m(Reading database ... 65%\u001b[0m\n",
      "\u001b[34m(Reading database ... 70%\u001b[0m\n",
      "\u001b[34m(Reading database ... 75%\u001b[0m\n",
      "\u001b[34m(Reading database ... 80%\u001b[0m\n",
      "\u001b[34m(Reading database ... 85%\u001b[0m\n",
      "\u001b[34m(Reading database ... 90%\u001b[0m\n",
      "\u001b[34m(Reading database ... 95%\u001b[0m\n",
      "\u001b[34m(Reading database ... 100%#015(Reading database ... 45301 files and directories currently installed.)\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../00-libslang2_2.3.2-4_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libslang2:amd64 (2.3.2-4) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsodium23:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../01-libsodium23_1.0.18-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsodium23:amd64 (1.0.18-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libusb-1.0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../02-libusb-1.0-0_2%3a1.0.23-2build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libusb-1.0-0:amd64 (2:1.0.23-2build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libaom0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../03-libaom0_1.0.0.errata1-3build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libaom0:amd64 (1.0.0.errata1-3build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libva2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../04-libva2_2.7.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libva2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libva-drm2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../05-libva-drm2_2.7.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libva-drm2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libva-x11-2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../06-libva-x11-2_2.7.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libva-x11-2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libvdpau1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../07-libvdpau1_1.3-1ubuntu2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libvdpau1:amd64 (1.3-1ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package ocl-icd-libopencl1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../08-ocl-icd-libopencl1_2.2.11-1ubuntu1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking ocl-icd-libopencl1:amd64 (2.2.11-1ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavutil56:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../09-libavutil56_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavutil56:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libcodec2-0.9:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../10-libcodec2-0.9_0.9.2-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libcodec2-0.9:amd64 (0.9.2-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libopenjp2-7:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../11-libopenjp2-7_2.3.1-1ubuntu4.20.04.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libopenjp2-7:amd64 (2.3.1-1ubuntu4.20.04.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libopus0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../12-libopus0_1.3.1-0ubuntu1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libopus0:amd64 (1.3.1-0ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libshine3:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../13-libshine3_3.1.1-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libshine3:amd64 (3.1.1-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsnappy1v5:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../14-libsnappy1v5_1.1.8-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsnappy1v5:amd64 (1.1.8-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libspeex1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../15-libspeex1_1.2~rc1.2-1.1ubuntu1.20.04.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libspeex1:amd64 (1.2~rc1.2-1.1ubuntu1.20.04.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsoxr0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../16-libsoxr0_0.1.3-2build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsoxr0:amd64 (0.1.3-2build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libswresample3:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../17-libswresample3_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libswresample3:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libtheora0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../18-libtheora0_1.1.1+dfsg.1-15ubuntu2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libtheora0:amd64 (1.1.1+dfsg.1-15ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libvpx6:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../19-libvpx6_1.8.2-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libvpx6:amd64 (1.8.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libx264-155:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../20-libx264-155_2%3a0.155.2917+git0a84d98-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libx264-155:amd64 (2:0.155.2917+git0a84d98-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libx265-179:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../21-libx265-179_3.2.1-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libx265-179:amd64 (3.2.1-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libxvidcore4:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../22-libxvidcore4_2%3a1.3.7-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libxvidcore4:amd64 (2:1.3.7-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libzvbi-common.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../23-libzvbi-common_0.2.35-17_all.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libzvbi-common (0.2.35-17) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libzvbi0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../24-libzvbi0_0.2.35-17_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libzvbi0:amd64 (0.2.35-17) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavcodec58:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../25-libavcodec58_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavcodec58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libraw1394-11:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../26-libraw1394-11_2.1.2-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libraw1394-11:amd64 (2.1.2-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavc1394-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../27-libavc1394-0_0.5.4-5_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavc1394-0:amd64 (0.5.4-5) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libass9:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../28-libass9_1%3a0.14.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libass9:amd64 (1:0.14.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libbluray2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../29-libbluray2_1%3a1.2.0-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libbluray2:amd64 (1:1.2.0-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libchromaprint1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../30-libchromaprint1_1.4.3-3build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libchromaprint1:amd64 (1.4.3-3build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libgme0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../31-libgme0_0.6.2-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libgme0:amd64 (0.6.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libmpg123-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../32-libmpg123-0_1.25.13-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libmpg123-0:amd64 (1.25.13-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libopenmpt0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../33-libopenmpt0_0.4.11-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libopenmpt0:amd64 (0.4.11-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libssh-gcrypt-4:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../34-libssh-gcrypt-4_0.9.3-2ubuntu2.2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libssh-gcrypt-4:amd64 (0.9.3-2ubuntu2.2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavformat58:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../35-libavformat58_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavformat58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libbs2b0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../36-libbs2b0_3.1.0+dfsg-2.2build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libbs2b0:amd64 (3.1.0+dfsg-2.2build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libflite1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../37-libflite1_2.1-release-3_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libflite1:amd64 (2.1-release-3) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libserd-0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../38-libserd-0-0_0.30.2-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libserd-0-0:amd64 (0.30.2-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsord-0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../39-libsord-0-0_0.16.4-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsord-0-0:amd64 (0.16.4-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsratom-0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../40-libsratom-0-0_0.6.4-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsratom-0-0:amd64 (0.6.4-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package liblilv-0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../41-liblilv-0-0_0.24.6-1ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking liblilv-0-0:amd64 (0.24.6-1ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libmysofa1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../42-libmysofa1_1.0~dfsg0-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libmysofa1:amd64 (1.0~dfsg0-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libpostproc55:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../43-libpostproc55_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libpostproc55:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsamplerate0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../44-libsamplerate0_0.1.9-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsamplerate0:amd64 (0.1.9-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package librubberband2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../45-librubberband2_1.8.2-1build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking librubberband2:amd64 (1.8.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libswscale5:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../46-libswscale5_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libswscale5:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libvidstab1.1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../47-libvidstab1.1_1.1.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libvidstab1.1:amd64 (1.1.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libnorm1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../48-libnorm1_1.5.8+dfsg2-2build1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libnorm1:amd64 (1.5.8+dfsg2-2build1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libpgm-5.2-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../49-libpgm-5.2-0_5.2.122~dfsg-3ubuntu1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libpgm-5.2-0:amd64 (5.2.122~dfsg-3ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libzmq5:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../50-libzmq5_4.3.2-2ubuntu1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libzmq5:amd64 (4.3.2-2ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavfilter7:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../51-libavfilter7_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavfilter7:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libcaca0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../52-libcaca0_0.99.beta19-2.1ubuntu1.20.04.2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libcaca0:amd64 (0.99.beta19-2.1ubuntu1.20.04.2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libcdio18:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../53-libcdio18_2.0.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libcdio18:amd64 (2.0.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libcdio-cdda2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../54-libcdio-cdda2_10.2+2.0.0-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libcdio-cdda2:amd64 (10.2+2.0.0-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libcdio-paranoia2:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../55-libcdio-paranoia2_10.2+2.0.0-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libcdio-paranoia2:amd64 (10.2+2.0.0-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libdc1394-22:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../56-libdc1394-22_2.2.5-2.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libdc1394-22:amd64 (2.2.5-2.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libiec61883-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../57-libiec61883-0_1.2.0-3_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libiec61883-0:amd64 (1.2.0-3) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libjack-jackd2-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../58-libjack-jackd2-0_1.9.12~dfsg-2ubuntu2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libjack-jackd2-0:amd64 (1.9.12~dfsg-2ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libopenal-data.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../59-libopenal-data_1%3a1.19.1-1_all.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libopenal-data (1:1.19.1-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsndio7.0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../60-libsndio7.0_1.5.0-3_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsndio7.0:amd64 (1.5.0-3) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libopenal1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../61-libopenal1_1%3a1.19.1-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libopenal1:amd64 (1:1.19.1-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libxss1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../62-libxss1_1%3a1.2.3-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libxss1:amd64 (1:1.2.3-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libsdl2-2.0-0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../63-libsdl2-2.0-0_2.0.10+dfsg1-3_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libsdl2-2.0-0:amd64 (2.0.10+dfsg1-3) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libxcb-shape0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../64-libxcb-shape0_1.14-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libxcb-shape0:amd64 (1.14-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libxv1:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../65-libxv1_2%3a1.0.11-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libxv1:amd64 (2:1.0.11-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavdevice58:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../66-libavdevice58_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavdevice58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libavresample4:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../67-libavresample4_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libavresample4:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package ffmpeg.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../68-ffmpeg_7%3a4.2.7-0ubuntu0.1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking ffmpeg (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libigdgmm11:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../69-libigdgmm11_20.1.1+ds1-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libigdgmm11:amd64 (20.1.1+ds1-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package intel-media-va-driver:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../70-intel-media-va-driver_20.1.1+dfsg1-1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking intel-media-va-driver:amd64 (20.1.1+dfsg1-1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libaacs0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../71-libaacs0_0.9.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libaacs0:amd64 (0.9.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package libbdplus0:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../72-libbdplus0_0.1.2-3_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking libbdplus0:amd64 (0.1.2-3) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package mesa-va-drivers:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../73-mesa-va-drivers_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking mesa-va-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package mesa-vdpau-drivers:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../74-mesa-vdpau-drivers_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking mesa-vdpau-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package i965-va-driver:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../75-i965-va-driver_2.4.0-0ubuntu1_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking i965-va-driver:amd64 (2.4.0-0ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package va-driver-all:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../76-va-driver-all_2.7.0-2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking va-driver-all:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSelecting previously unselected package vdpau-driver-all:amd64.\u001b[0m\n",
      "\u001b[34mPreparing to unpack .../77-vdpau-driver-all_1.3-1ubuntu2_amd64.deb ...\u001b[0m\n",
      "\u001b[34mUnpacking vdpau-driver-all:amd64 (1.3-1ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSetting up libgme0:amd64 (0.6.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libssh-gcrypt-4:amd64 (0.9.3-2ubuntu2.2) ...\u001b[0m\n",
      "\u001b[34mSetting up libraw1394-11:amd64 (2.1.2-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libsodium23:amd64 (1.0.18-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libmpg123-0:amd64 (1.25.13-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libspeex1:amd64 (1.2~rc1.2-1.1ubuntu1.20.04.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libshine3:amd64 (3.1.1-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libx264-155:amd64 (2:0.155.2917+git0a84d98-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libx265-179:amd64 (3.2.1-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libsoxr0:amd64 (0.1.3-2build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libaom0:amd64 (1.0.0.errata1-3build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libnorm1:amd64 (1.5.8+dfsg2-2build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libmysofa1:amd64 (1.0~dfsg0-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libxcb-shape0:amd64 (1.14-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libcdio18:amd64 (2.0.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libxvidcore4:amd64 (2:1.3.7-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libsnappy1v5:amd64 (1.1.8-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libass9:amd64 (1:0.14.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libslang2:amd64 (2.3.2-4) ...\u001b[0m\n",
      "\u001b[34mSetting up libva2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libigdgmm11:amd64 (20.1.1+ds1-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libcodec2-0.9:amd64 (0.9.2-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libopus0:amd64 (1.3.1-0ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSetting up intel-media-va-driver:amd64 (20.1.1+dfsg1-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libxv1:amd64 (2:1.0.11-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libaacs0:amd64 (0.9.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libsndio7.0:amd64 (1.5.0-3) ...\u001b[0m\n",
      "\u001b[34mSetting up libbdplus0:amd64 (0.1.2-3) ...\u001b[0m\n",
      "\u001b[34mSetting up libvidstab1.1:amd64 (1.1.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libflite1:amd64 (2.1-release-3) ...\u001b[0m\n",
      "\u001b[34mSetting up libva-drm2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up ocl-icd-libopencl1:amd64 (2.2.11-1ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSetting up libvpx6:amd64 (1.8.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libvdpau1:amd64 (1.3-1ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSetting up libbs2b0:amd64 (3.1.0+dfsg-2.2build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libtheora0:amd64 (1.1.1+dfsg.1-15ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSetting up libopenjp2-7:amd64 (2.3.1-1ubuntu4.20.04.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libopenal-data (1:1.19.1-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libxss1:amd64 (1:1.2.3-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libusb-1.0-0:amd64 (2:1.0.23-2build1) ...\u001b[0m\n",
      "\u001b[34mSetting up mesa-va-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\u001b[0m\n",
      "\u001b[34mSetting up libbluray2:amd64 (1:1.2.0-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libsdl2-2.0-0:amd64 (2.0.10+dfsg1-3) ...\u001b[0m\n",
      "\u001b[34mSetting up libsamplerate0:amd64 (0.1.9-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libva-x11-2:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libopenmpt0:amd64 (0.4.11-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libzvbi-common (0.2.35-17) ...\u001b[0m\n",
      "\u001b[34mSetting up i965-va-driver:amd64 (2.4.0-0ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSetting up libpgm-5.2-0:amd64 (5.2.122~dfsg-3ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSetting up libiec61883-0:amd64 (1.2.0-3) ...\u001b[0m\n",
      "\u001b[34mSetting up libserd-0-0:amd64 (0.30.2-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavc1394-0:amd64 (0.5.4-5) ...\u001b[0m\n",
      "\u001b[34mSetting up mesa-vdpau-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\u001b[0m\n",
      "\u001b[34mSetting up libzvbi0:amd64 (0.2.35-17) ...\u001b[0m\n",
      "\u001b[34mSetting up libzmq5:amd64 (4.3.2-2ubuntu1) ...\u001b[0m\n",
      "\u001b[34mSetting up libcaca0:amd64 (0.99.beta19-2.1ubuntu1.20.04.2) ...\u001b[0m\n",
      "\u001b[34mSetting up libcdio-cdda2:amd64 (10.2+2.0.0-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libcdio-paranoia2:amd64 (10.2+2.0.0-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libdc1394-22:amd64 (2.2.5-2.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libopenal1:amd64 (1:1.19.1-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavutil56:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up va-driver-all:amd64 (2.7.0-2) ...\u001b[0m\n",
      "\u001b[34mSetting up libpostproc55:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up librubberband2:amd64 (1.8.2-1build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libjack-jackd2-0:amd64 (1.9.12~dfsg-2ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSetting up vdpau-driver-all:amd64 (1.3-1ubuntu2) ...\u001b[0m\n",
      "\u001b[34mSetting up libsord-0-0:amd64 (0.16.4-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libsratom-0-0:amd64 (0.6.4-1) ...\u001b[0m\n",
      "\u001b[34mSetting up libswscale5:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up liblilv-0-0:amd64 (0.24.6-1ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libswresample3:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavresample4:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavcodec58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libchromaprint1:amd64 (1.4.3-3build1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavformat58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavfilter7:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up libavdevice58:amd64 (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mSetting up ffmpeg (7:4.2.7-0ubuntu0.1) ...\u001b[0m\n",
      "\u001b[34mProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:52 optimizers:66] Could not import distributed_fused_adam optimizer from Apex\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:54 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:55 nemo_logging:349] /opt/conda/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 speech_to_text_ctc:89] Hydra config: name: Conformer-CTC-Char1\n",
      "    model:\n",
      "      sample_rate: 16000\n",
      "      labels:\n",
      "      - ' '\n",
      "      - a\n",
      "      - b\n",
      "      - c\n",
      "      - d\n",
      "      - e\n",
      "      - f\n",
      "      - g\n",
      "      - h\n",
      "      - i\n",
      "      - j\n",
      "      - k\n",
      "      - l\n",
      "      - m\n",
      "      - 'n'\n",
      "      - o\n",
      "      - p\n",
      "      - q\n",
      "      - r\n",
      "      - s\n",
      "      - t\n",
      "      - u\n",
      "      - v\n",
      "      - w\n",
      "      - x\n",
      "      - 'y'\n",
      "      - z\n",
      "      - ''''\n",
      "      log_prediction: true\n",
      "      ctc_reduction: mean_batch\n",
      "      skip_nan_grad: false\n",
      "      train_ds:\n",
      "        manifest_filepath: /opt/ml/input/data/training/an4/train_manifest.json\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "        trim_silence: false\n",
      "        max_duration: 16.7\n",
      "        min_duration: 0.1\n",
      "        is_tarred: false\n",
      "        tarred_audio_filepaths: null\n",
      "        shuffle_n: 2048\n",
      "        bucketing_strategy: synced_randomized\n",
      "        bucketing_batch_size: null\n",
      "      validation_ds:\n",
      "        manifest_filepath: /opt/ml/input/data/testing/an4/test_manifest.json\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      test_ds:\n",
      "        manifest_filepath: null\n",
      "        labels: ${model.labels}\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        batch_size: 16\n",
      "        shuffle: false\n",
      "        num_workers: 8\n",
      "        pin_memory: true\n",
      "      preprocessor:\n",
      "        _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "        sample_rate: ${model.sample_rate}\n",
      "        normalize: per_feature\n",
      "        window_size: 0.025\n",
      "        window_stride: 0.01\n",
      "        window: hann\n",
      "        features: 80\n",
      "        n_fft: 512\n",
      "        log: true\n",
      "        frame_splicing: 1\n",
      "        dither: 1.0e-05\n",
      "        pad_to: 0\n",
      "        pad_value: 0.0\n",
      "      spec_augment:\n",
      "        _target_: nemo.collections.asr.modules.SpectrogramAugmentation\n",
      "        freq_masks: 2\n",
      "        time_masks: 5\n",
      "        freq_width: 27\n",
      "        time_width: 0.05\n",
      "      encoder:\n",
      "        _target_: nemo.collections.asr.modules.ConformerEncoder\n",
      "        feat_in: ${model.preprocessor.features}\n",
      "        feat_out: -1\n",
      "        n_layers: 8\n",
      "        d_model: 256\n",
      "        subsampling: striding\n",
      "        subsampling_factor: 4\n",
      "        subsampling_conv_channels: -1\n",
      "        causal_downsampling: false\n",
      "        ff_expansion_factor: 4\n",
      "        self_attention_model: rel_pos\n",
      "        n_heads: 8\n",
      "        att_context_size:\n",
      "        - -1\n",
      "        - -1\n",
      "        att_context_style: regular\n",
      "        xscaling: true\n",
      "        untie_biases: true\n",
      "        pos_emb_max_len: 5000\n",
      "        conv_kernel_size: 31\n",
      "        conv_norm_type: batch_norm\n",
      "        conv_context_size: null\n",
      "        dropout: 0.1\n",
      "        dropout_pre_encoder: 0.1\n",
      "        dropout_emb: 0.0\n",
      "        dropout_att: 0.1\n",
      "        stochastic_depth_drop_prob: 0.0\n",
      "        stochastic_depth_mode: linear\n",
      "        stochastic_depth_start_layer: 1\n",
      "      decoder:\n",
      "        _target_: nemo.collections.asr.modules.ConvASRDecoder\n",
      "        feat_in: null\n",
      "        num_classes: -1\n",
      "        vocabulary: ${model.labels}\n",
      "      interctc:\n",
      "        loss_weights: []\n",
      "        apply_at_layers: []\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 2.0\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.98\n",
      "        weight_decay: 0.001\n",
      "        sched:\n",
      "          name: NoamAnnealing\n",
      "          d_model: ${model.encoder.d_model}\n",
      "          warmup_steps: 10000\n",
      "          warmup_ratio: null\n",
      "          min_lr: 1.0e-06\n",
      "      n_heads: 4\n",
      "    trainer:\n",
      "      devices: -1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 2\n",
      "      max_steps: -1\n",
      "      val_check_interval: 1.0\n",
      "      accelerator: gpu\n",
      "      strategy: null\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 0.0\n",
      "      precision: 32\n",
      "      log_every_n_steps: 10\n",
      "      enable_progress_bar: true\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      check_val_every_n_epoch: 1\n",
      "      sync_batchnorm: true\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "      benchmark: false\n",
      "    exp_manager:\n",
      "      exp_dir: /opt/ml/model/\n",
      "      name: ${name}\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        monitor: val_wer\n",
      "        mode: min\n",
      "        save_top_k: 5\n",
      "        always_save_nemo: true\n",
      "      resume_if_exists: true\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: null\n",
      "        project: null\n",
      "    init_from_nemo_model: /opt/ml/input/data/pretrained/CTC.nemo\u001b[0m\n",
      "\u001b[34mGPU available: True (cuda), used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mIPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34mHPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:55 exp_manager:710] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:55 exp_manager:562] There was no checkpoint folder at checkpoint_dir :/opt/ml/model/Conformer-CTC-Char1/checkpoints. Training from scratch.\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 exp_manager:373] Experiments will be logged at /opt/ml/model/Conformer-CTC-Char1\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 exp_manager:791] TensorboardLogger has been set up\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 collections:193] Dataset loaded with 948 files totalling 0.71 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 collections:194] 0 files were filtered totalling 0.00 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 collections:193] Dataset loaded with 130 files totalling 0.10 hours\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 collections:194] 0 files were filtered totalling 0.00 hours\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:55 audio_to_text_dataset:576] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'labels': [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\"], 'sample_rate': 16000, 'batch_size': 16, 'shuffle': False, 'num_workers': 8, 'pin_memory': True}\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 features:287] PADDING: 0\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 ctc_models:64] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 28\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:55 conv_asr:428] num_classes of ConvASRDecoder is set to the size of the vocabulary: 28.\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:56 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /opt/ml/input/data/training/an4/train_manifest.json\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:56 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /opt/ml/input/data/testing/an4/test_manifest.json\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\u001b[0m\n",
      "\u001b[34m[NeMo W 2023-03-22 10:58:56 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    labels:\n",
      "    - ' '\n",
      "    - a\n",
      "    - b\n",
      "    - c\n",
      "    - d\n",
      "    - e\n",
      "    - f\n",
      "    - g\n",
      "    - h\n",
      "    - i\n",
      "    - j\n",
      "    - k\n",
      "    - l\n",
      "    - m\n",
      "    - 'n'\n",
      "    - o\n",
      "    - p\n",
      "    - q\n",
      "    - r\n",
      "    - s\n",
      "    - t\n",
      "    - u\n",
      "    - v\n",
      "    - w\n",
      "    - x\n",
      "    - 'y'\n",
      "    - z\n",
      "    - ''''\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:56 features:287] PADDING: 0\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:56 ctc_models:64] \n",
      "    Replacing placeholder number of classes (-1) with actual number of classes - 28\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:56 conv_asr:428] num_classes of ConvASRDecoder is set to the size of the vocabulary: 28.\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:56 save_restore_connector:247] Model EncDecCTCModel was successfully restored from /opt/ml/input/data/pretrained/CTC.nemo.\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:56 modelPT:1221] Model checkpoint restored from nemo file with path : `/opt/ml/input/data/pretrained/CTC.nemo`\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:58 modelPT:722] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.98]\n",
      "        capturable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        lr: 2.0\n",
      "        maximize: False\n",
      "        weight_decay: 0.001\n",
      "    )\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:58:58 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.NoamAnnealing object at 0x7f254414ee50>\" \n",
      "    will be used during training (effective maximum steps = 120) - \n",
      "    Parameters : \n",
      "    (d_model: 256\n",
      "    warmup_steps: 10000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 120\n",
      "    )\u001b[0m\n",
      "\u001b[34m| Name              | Type                              | Params\u001b[0m\n",
      "\u001b[34m------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \u001b[0m\n",
      "\u001b[34m1 | encoder           | ConformerEncoder                  | 14.6 M\u001b[0m\n",
      "\u001b[34m2 | decoder           | ConvASRDecoder                    | 7.5 K \u001b[0m\n",
      "\u001b[34m3 | loss              | CTCLoss                           | 0     \u001b[0m\n",
      "\u001b[34m4 | spec_augmentation | SpectrogramAugmentation           | 0     \u001b[0m\n",
      "\u001b[34m5 | _wer              | WER                               | 0     \u001b[0m\n",
      "\u001b[34m------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m14.6 M    Trainable params\u001b[0m\n",
      "\u001b[34m0         Non-trainable params\u001b[0m\n",
      "\u001b[34m14.6 M    Total params\u001b[0m\n",
      "\u001b[34m58.492    Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34mTraining: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mTraining:   0%|          | 0/69 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mEpoch 0:   0%|          | 0/69 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-03-22 10:58:58.555: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.0.dev0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mUsing NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-03-22 10:58:58.581 algo-1:73 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-03-22 10:58:58.601 algo-1:73 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34mEpoch 0:   1%|▏         | 1/69 [00:02<03:03,  2.70s/it]\u001b[0m\n",
      "\u001b[34mEpoch 0:   1%|▏         | 1/69 [00:02<03:03,  2.70s/it, loss=72.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   3%|▎         | 2/69 [00:02<01:35,  1.43s/it, loss=72.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   3%|▎         | 2/69 [00:02<01:35,  1.43s/it, loss=62.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   4%|▍         | 3/69 [00:03<01:08,  1.03s/it, loss=62.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   4%|▍         | 3/69 [00:03<01:08,  1.03s/it, loss=61, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   6%|▌         | 4/69 [00:03<00:53,  1.22it/s, loss=61, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   6%|▌         | 4/69 [00:03<00:53,  1.22it/s, loss=58.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   7%|▋         | 5/69 [00:03<00:43,  1.46it/s, loss=58.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   7%|▋         | 5/69 [00:03<00:43,  1.46it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   9%|▊         | 6/69 [00:03<00:37,  1.68it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   9%|▊         | 6/69 [00:03<00:37,  1.68it/s, loss=57.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  10%|█         | 7/69 [00:03<00:33,  1.85it/s, loss=57.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  10%|█         | 7/69 [00:03<00:33,  1.85it/s, loss=56.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  12%|█▏        | 8/69 [00:03<00:30,  2.03it/s, loss=56.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  12%|█▏        | 8/69 [00:03<00:30,  2.03it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  13%|█▎        | 9/69 [00:04<00:27,  2.15it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  13%|█▎        | 9/69 [00:04<00:27,  2.15it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:02 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:02 wer:1169] reference:one five two one three\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:02 wer:1170] predicted:o\u001b[0m\n",
      "\u001b[34mEpoch 0:  14%|█▍        | 10/69 [00:04<00:26,  2.25it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  14%|█▍        | 10/69 [00:04<00:26,  2.25it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  16%|█▌        | 11/69 [00:04<00:24,  2.34it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  16%|█▌        | 11/69 [00:04<00:24,  2.34it/s, loss=56, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  17%|█▋        | 12/69 [00:04<00:23,  2.45it/s, loss=56, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  17%|█▋        | 12/69 [00:04<00:23,  2.45it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  19%|█▉        | 13/69 [00:05<00:22,  2.53it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  19%|█▉        | 13/69 [00:05<00:22,  2.53it/s, loss=56.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  20%|██        | 14/69 [00:05<00:20,  2.65it/s, loss=56.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  20%|██        | 14/69 [00:05<00:20,  2.65it/s, loss=55.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  22%|██▏       | 15/69 [00:05<00:19,  2.74it/s, loss=55.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  22%|██▏       | 15/69 [00:05<00:19,  2.73it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  23%|██▎       | 16/69 [00:05<00:18,  2.83it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  23%|██▎       | 16/69 [00:05<00:18,  2.83it/s, loss=55.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  25%|██▍       | 17/69 [00:05<00:17,  2.91it/s, loss=55.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  25%|██▍       | 17/69 [00:05<00:17,  2.91it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  26%|██▌       | 18/69 [00:06<00:17,  3.00it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  26%|██▌       | 18/69 [00:06<00:17,  3.00it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  28%|██▊       | 19/69 [00:06<00:16,  3.04it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  28%|██▊       | 19/69 [00:06<00:16,  3.04it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:04 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:04 wer:1169] reference:four five two eight five one eight\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:04 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 0:  29%|██▉       | 20/69 [00:06<00:15,  3.12it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  29%|██▉       | 20/69 [00:06<00:15,  3.12it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  30%|███       | 21/69 [00:06<00:15,  3.19it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  30%|███       | 21/69 [00:06<00:15,  3.19it/s, loss=54.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  32%|███▏      | 22/69 [00:06<00:14,  3.26it/s, loss=54.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  32%|███▏      | 22/69 [00:06<00:14,  3.26it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  33%|███▎      | 23/69 [00:06<00:13,  3.32it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  33%|███▎      | 23/69 [00:06<00:13,  3.32it/s, loss=54.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  35%|███▍      | 24/69 [00:07<00:13,  3.40it/s, loss=54.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  35%|███▍      | 24/69 [00:07<00:13,  3.40it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  36%|███▌      | 25/69 [00:07<00:12,  3.45it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  36%|███▌      | 25/69 [00:07<00:12,  3.45it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  38%|███▊      | 26/69 [00:07<00:12,  3.51it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  38%|███▊      | 26/69 [00:07<00:12,  3.51it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  39%|███▉      | 27/69 [00:07<00:11,  3.56it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  39%|███▉      | 27/69 [00:07<00:11,  3.56it/s, loss=53.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  41%|████      | 28/69 [00:07<00:11,  3.61it/s, loss=53.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  41%|████      | 28/69 [00:07<00:11,  3.61it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  42%|████▏     | 29/69 [00:07<00:10,  3.65it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  42%|████▏     | 29/69 [00:07<00:10,  3.65it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:06 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:06 wer:1169] reference:one five two one seven\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:06 wer:1170] predicted:      e\u001b[0m\n",
      "\u001b[34mEpoch 0:  43%|████▎     | 30/69 [00:08<00:10,  3.67it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  43%|████▎     | 30/69 [00:08<00:10,  3.67it/s, loss=54, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  45%|████▍     | 31/69 [00:08<00:10,  3.68it/s, loss=54, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  45%|████▍     | 31/69 [00:08<00:10,  3.68it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  46%|████▋     | 32/69 [00:08<00:09,  3.73it/s, loss=53.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  46%|████▋     | 32/69 [00:08<00:09,  3.73it/s, loss=53.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  48%|████▊     | 33/69 [00:08<00:09,  3.77it/s, loss=53.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  48%|████▊     | 33/69 [00:08<00:09,  3.77it/s, loss=52.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  49%|████▉     | 34/69 [00:08<00:09,  3.79it/s, loss=52.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  49%|████▉     | 34/69 [00:08<00:09,  3.79it/s, loss=52.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  51%|█████     | 35/69 [00:09<00:08,  3.82it/s, loss=52.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  51%|█████     | 35/69 [00:09<00:08,  3.82it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  52%|█████▏    | 36/69 [00:09<00:08,  3.83it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  52%|█████▏    | 36/69 [00:09<00:08,  3.82it/s, loss=52.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  54%|█████▎    | 37/69 [00:09<00:08,  3.83it/s, loss=52.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  54%|█████▎    | 37/69 [00:09<00:08,  3.83it/s, loss=52.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  55%|█████▌    | 38/69 [00:09<00:08,  3.86it/s, loss=52.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  55%|█████▌    | 38/69 [00:09<00:08,  3.86it/s, loss=51.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  57%|█████▋    | 39/69 [00:10<00:07,  3.86it/s, loss=51.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  57%|█████▋    | 39/69 [00:10<00:07,  3.86it/s, loss=51.7, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:08 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:08 wer:1169] reference:b o u q u e t\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:08 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 0:  58%|█████▊    | 40/69 [00:10<00:07,  3.90it/s, loss=51.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  58%|█████▊    | 40/69 [00:10<00:07,  3.90it/s, loss=52, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  59%|█████▉    | 41/69 [00:10<00:07,  3.94it/s, loss=52, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  59%|█████▉    | 41/69 [00:10<00:07,  3.94it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  61%|██████    | 42/69 [00:10<00:06,  3.97it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  61%|██████    | 42/69 [00:10<00:06,  3.97it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  62%|██████▏   | 43/69 [00:10<00:06,  4.00it/s, loss=52.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  62%|██████▏   | 43/69 [00:10<00:06,  4.00it/s, loss=53, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  64%|██████▍   | 44/69 [00:10<00:06,  4.03it/s, loss=53, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  64%|██████▍   | 44/69 [00:10<00:06,  4.03it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  65%|██████▌   | 45/69 [00:11<00:05,  4.07it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  65%|██████▌   | 45/69 [00:11<00:05,  4.07it/s, loss=54, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  67%|██████▋   | 46/69 [00:11<00:05,  4.09it/s, loss=54, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  67%|██████▋   | 46/69 [00:11<00:05,  4.09it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  68%|██████▊   | 47/69 [00:11<00:05,  4.09it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  68%|██████▊   | 47/69 [00:11<00:05,  4.09it/s, loss=55.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  70%|██████▉   | 48/69 [00:11<00:05,  4.12it/s, loss=55.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  70%|██████▉   | 48/69 [00:11<00:05,  4.12it/s, loss=54.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  71%|███████   | 49/69 [00:11<00:04,  4.14it/s, loss=54.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  71%|███████   | 49/69 [00:11<00:04,  4.14it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:10 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:10 wer:1169] reference:o l d b a r n d r i v e\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:10 wer:1170] predicted:  t\u001b[0m\n",
      "\u001b[34mEpoch 0:  72%|███████▏  | 50/69 [00:12<00:04,  4.16it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  72%|███████▏  | 50/69 [00:12<00:04,  4.16it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  74%|███████▍  | 51/69 [00:12<00:04,  4.18it/s, loss=53.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  74%|███████▍  | 51/69 [00:12<00:04,  4.18it/s, loss=53.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  75%|███████▌  | 52/69 [00:12<00:04,  4.19it/s, loss=53.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  75%|███████▌  | 52/69 [00:12<00:04,  4.19it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  77%|███████▋  | 53/69 [00:12<00:03,  4.19it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  77%|███████▋  | 53/69 [00:12<00:03,  4.19it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  78%|███████▊  | 54/69 [00:12<00:03,  4.20it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  78%|███████▊  | 54/69 [00:12<00:03,  4.20it/s, loss=55.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  80%|███████▉  | 55/69 [00:13<00:03,  4.23it/s, loss=55.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  80%|███████▉  | 55/69 [00:13<00:03,  4.22it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  81%|████████  | 56/69 [00:13<00:03,  4.24it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  81%|████████  | 56/69 [00:13<00:03,  4.24it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  83%|████████▎ | 57/69 [00:13<00:02,  4.27it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  83%|████████▎ | 57/69 [00:13<00:02,  4.27it/s, loss=56.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  84%|████████▍ | 58/69 [00:13<00:02,  4.27it/s, loss=56.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  84%|████████▍ | 58/69 [00:13<00:02,  4.27it/s, loss=57.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  86%|████████▌ | 59/69 [00:13<00:02,  4.29it/s, loss=57.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  86%|████████▌ | 59/69 [00:13<00:02,  4.29it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:v e r k e thirty five thirty\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 0:  87%|████████▋ | 60/69 [00:13<00:02,  4.33it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:  87%|████████▋ | 60/69 [00:13<00:02,  4.33it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mValidation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34mValidation:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  11%|█         | 1/9 [00:00<00:00, 14.96it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  88%|████████▊ | 61/69 [00:14<00:01,  4.30it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:j p e g four\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  22%|██▏       | 2/9 [00:00<00:00, 17.13it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  90%|████████▉ | 62/69 [00:14<00:01,  4.35it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:v a n e s s a\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  33%|███▎      | 3/9 [00:00<00:00, 18.73it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  91%|█████████▏| 63/69 [00:14<00:01,  4.41it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:p i t t s b u r g h\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  44%|████▍     | 4/9 [00:00<00:00, 18.30it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  93%|█████████▎| 64/69 [00:14<00:01,  4.46it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:march seven nineteen sixty seven\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  56%|█████▌    | 5/9 [00:00<00:00, 19.15it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  94%|█████████▍| 65/69 [00:14<00:00,  4.52it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:rubout c b w x v four\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  67%|██████▋   | 6/9 [00:00<00:00, 19.43it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  96%|█████████▌| 66/69 [00:14<00:00,  4.57it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:m y e r s\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  78%|███████▊  | 7/9 [00:00<00:00, 20.23it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  97%|█████████▋| 67/69 [00:14<00:00,  4.63it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1169] reference:p h i n n e y\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:12 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  89%|████████▉ | 8/9 [00:00<00:00, 20.37it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0:  99%|█████████▊| 68/69 [00:14<00:00,  4.68it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:13 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:13 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:13 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 21.56it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0: 100%|██████████| 69/69 [00:14<00:00,  4.74it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0: 100%|██████████| 69/69 [00:14<00:00,  4.74it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mEpoch 0, global step 60: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=0.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:13 exp_manager:972] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:13 exp_manager:972] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34mEpoch 0: 100%|██████████| 69/69 [00:15<00:00,  4.37it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 0:   0%|          | 0/69 [00:00<?, ?it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   0%|          | 0/69 [00:00<?, ?it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   1%|▏         | 1/69 [00:00<00:31,  2.13it/s, loss=58.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   1%|▏         | 1/69 [00:00<00:32,  2.12it/s, loss=57.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   3%|▎         | 2/69 [00:00<00:23,  2.85it/s, loss=57.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   3%|▎         | 2/69 [00:00<00:23,  2.85it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   4%|▍         | 3/69 [00:00<00:20,  3.17it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   4%|▍         | 3/69 [00:00<00:20,  3.17it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   6%|▌         | 4/69 [00:01<00:18,  3.57it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   6%|▌         | 4/69 [00:01<00:18,  3.57it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   7%|▋         | 5/69 [00:01<00:16,  3.90it/s, loss=57.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   7%|▋         | 5/69 [00:01<00:16,  3.90it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   9%|▊         | 6/69 [00:01<00:15,  4.19it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:   9%|▊         | 6/69 [00:01<00:15,  4.19it/s, loss=57.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  10%|█         | 7/69 [00:01<00:14,  4.17it/s, loss=57.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  10%|█         | 7/69 [00:01<00:14,  4.17it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  12%|█▏        | 8/69 [00:01<00:14,  4.17it/s, loss=57.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  12%|█▏        | 8/69 [00:01<00:14,  4.16it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  13%|█▎        | 9/69 [00:02<00:13,  4.33it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  13%|█▎        | 9/69 [00:02<00:13,  4.33it/s, loss=58.4, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:16 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:16 wer:1169] reference:h z a e three seven five one\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:16 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 1:  14%|█▍        | 10/69 [00:02<00:13,  4.39it/s, loss=58.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  14%|█▍        | 10/69 [00:02<00:13,  4.39it/s, loss=59.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  16%|█▌        | 11/69 [00:02<00:12,  4.51it/s, loss=59.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  16%|█▌        | 11/69 [00:02<00:12,  4.51it/s, loss=59.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  17%|█▋        | 12/69 [00:02<00:12,  4.47it/s, loss=59.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  17%|█▋        | 12/69 [00:02<00:12,  4.47it/s, loss=58.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  19%|█▉        | 13/69 [00:02<00:12,  4.52it/s, loss=58.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  19%|█▉        | 13/69 [00:02<00:12,  4.52it/s, loss=58, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  20%|██        | 14/69 [00:03<00:11,  4.63it/s, loss=58, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  20%|██        | 14/69 [00:03<00:11,  4.63it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  22%|██▏       | 15/69 [00:03<00:11,  4.67it/s, loss=57.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  22%|██▏       | 15/69 [00:03<00:11,  4.67it/s, loss=56.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  23%|██▎       | 16/69 [00:03<00:11,  4.75it/s, loss=56.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  23%|██▎       | 16/69 [00:03<00:11,  4.75it/s, loss=56.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  25%|██▍       | 17/69 [00:03<00:10,  4.79it/s, loss=56.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  25%|██▍       | 17/69 [00:03<00:10,  4.79it/s, loss=56.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  26%|██▌       | 18/69 [00:03<00:10,  4.75it/s, loss=56.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  26%|██▌       | 18/69 [00:03<00:10,  4.75it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  28%|██▊       | 19/69 [00:03<00:10,  4.80it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  28%|██▊       | 19/69 [00:03<00:10,  4.80it/s, loss=55, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:18 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:18 wer:1169] reference:four one two four two two three five seven eight\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:18 wer:1170] predicted: e\u001b[0m\n",
      "\u001b[34mEpoch 1:  29%|██▉       | 20/69 [00:04<00:10,  4.76it/s, loss=55, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  29%|██▉       | 20/69 [00:04<00:10,  4.76it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  30%|███       | 21/69 [00:04<00:10,  4.74it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  30%|███       | 21/69 [00:04<00:10,  4.74it/s, loss=54.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  32%|███▏      | 22/69 [00:04<00:09,  4.71it/s, loss=54.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  32%|███▏      | 22/69 [00:04<00:09,  4.71it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  33%|███▎      | 23/69 [00:04<00:09,  4.68it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  33%|███▎      | 23/69 [00:04<00:09,  4.68it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  35%|███▍      | 24/69 [00:05<00:09,  4.71it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  35%|███▍      | 24/69 [00:05<00:09,  4.71it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  36%|███▌      | 25/69 [00:05<00:09,  4.69it/s, loss=54.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  36%|███▌      | 25/69 [00:05<00:09,  4.69it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  38%|███▊      | 26/69 [00:05<00:09,  4.75it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  38%|███▊      | 26/69 [00:05<00:09,  4.75it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  39%|███▉      | 27/69 [00:05<00:08,  4.72it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  39%|███▉      | 27/69 [00:05<00:08,  4.72it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  41%|████      | 28/69 [00:05<00:08,  4.74it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  41%|████      | 28/69 [00:05<00:08,  4.74it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  42%|████▏     | 29/69 [00:06<00:08,  4.78it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  42%|████▏     | 29/69 [00:06<00:08,  4.78it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:20 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:20 wer:1169] reference:l u b i n s k i\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:20 wer:1170] predicted:  e\u001b[0m\n",
      "\u001b[34mEpoch 1:  43%|████▎     | 30/69 [00:06<00:08,  4.79it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  43%|████▎     | 30/69 [00:06<00:08,  4.79it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  45%|████▍     | 31/69 [00:06<00:07,  4.81it/s, loss=53.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  45%|████▍     | 31/69 [00:06<00:07,  4.81it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  46%|████▋     | 32/69 [00:06<00:07,  4.78it/s, loss=53.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  46%|████▋     | 32/69 [00:06<00:07,  4.78it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  48%|████▊     | 33/69 [00:06<00:07,  4.80it/s, loss=54.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  48%|████▊     | 33/69 [00:06<00:07,  4.80it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  49%|████▉     | 34/69 [00:07<00:07,  4.83it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  49%|████▉     | 34/69 [00:07<00:07,  4.83it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  51%|█████     | 35/69 [00:07<00:06,  4.86it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  51%|█████     | 35/69 [00:07<00:06,  4.86it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  52%|█████▏    | 36/69 [00:07<00:06,  4.87it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  52%|█████▏    | 36/69 [00:07<00:06,  4.87it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  54%|█████▎    | 37/69 [00:07<00:06,  4.91it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  54%|█████▎    | 37/69 [00:07<00:06,  4.91it/s, loss=55, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  55%|█████▌    | 38/69 [00:07<00:06,  4.89it/s, loss=55, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  55%|█████▌    | 38/69 [00:07<00:06,  4.89it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  57%|█████▋    | 39/69 [00:07<00:06,  4.91it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  57%|█████▋    | 39/69 [00:07<00:06,  4.91it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:22 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:22 wer:1169] reference:w a t e r b u r y\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:22 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 1:  58%|█████▊    | 40/69 [00:08<00:05,  4.93it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  58%|█████▊    | 40/69 [00:08<00:05,  4.93it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  59%|█████▉    | 41/69 [00:08<00:05,  4.95it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  59%|█████▉    | 41/69 [00:08<00:05,  4.95it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  61%|██████    | 42/69 [00:08<00:05,  4.96it/s, loss=55.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  61%|██████    | 42/69 [00:08<00:05,  4.96it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  62%|██████▏   | 43/69 [00:08<00:05,  4.96it/s, loss=55.4, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  62%|██████▏   | 43/69 [00:08<00:05,  4.96it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  64%|██████▍   | 44/69 [00:08<00:05,  4.94it/s, loss=55.3, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  64%|██████▍   | 44/69 [00:08<00:05,  4.94it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  65%|██████▌   | 45/69 [00:09<00:04,  4.91it/s, loss=54.7, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  65%|██████▌   | 45/69 [00:09<00:04,  4.91it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  67%|██████▋   | 46/69 [00:09<00:04,  4.93it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  67%|██████▋   | 46/69 [00:09<00:04,  4.93it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  68%|██████▊   | 47/69 [00:09<00:04,  4.94it/s, loss=55.9, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  68%|██████▊   | 47/69 [00:09<00:04,  4.94it/s, loss=56.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  70%|██████▉   | 48/69 [00:09<00:04,  4.95it/s, loss=56.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  70%|██████▉   | 48/69 [00:09<00:04,  4.95it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  71%|███████   | 49/69 [00:09<00:04,  4.96it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  71%|███████   | 49/69 [00:09<00:04,  4.96it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:24 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:24 wer:1169] reference:october twenty third nineteen sixty seven\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:24 wer:1170] predicted: t\u001b[0m\n",
      "\u001b[34mEpoch 1:  72%|███████▏  | 50/69 [00:10<00:03,  4.97it/s, loss=55.5, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  72%|███████▏  | 50/69 [00:10<00:03,  4.97it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  74%|███████▍  | 51/69 [00:10<00:03,  4.99it/s, loss=55.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  74%|███████▍  | 51/69 [00:10<00:03,  4.99it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  75%|███████▌  | 52/69 [00:10<00:03,  4.99it/s, loss=55.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  75%|███████▌  | 52/69 [00:10<00:03,  4.99it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  77%|███████▋  | 53/69 [00:10<00:03,  4.97it/s, loss=54.8, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  77%|███████▋  | 53/69 [00:10<00:03,  4.97it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  78%|███████▊  | 54/69 [00:10<00:03,  4.99it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  78%|███████▊  | 54/69 [00:10<00:03,  4.99it/s, loss=53.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  80%|███████▉  | 55/69 [00:11<00:02,  4.98it/s, loss=53.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  80%|███████▉  | 55/69 [00:11<00:02,  4.98it/s, loss=52.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  81%|████████  | 56/69 [00:11<00:02,  4.99it/s, loss=52.6, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  81%|████████  | 56/69 [00:11<00:02,  4.99it/s, loss=53, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  83%|████████▎ | 57/69 [00:11<00:02,  5.01it/s, loss=53, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  83%|████████▎ | 57/69 [00:11<00:02,  5.01it/s, loss=52.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  84%|████████▍ | 58/69 [00:11<00:02,  5.03it/s, loss=52.2, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  84%|████████▍ | 58/69 [00:11<00:02,  5.03it/s, loss=52.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  86%|████████▌ | 59/69 [00:11<00:01,  5.05it/s, loss=52.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  86%|████████▌ | 59/69 [00:11<00:01,  5.05it/s, loss=52, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:25 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:25 wer:1169] reference:h b g l seventy seven\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:25 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mEpoch 1:  87%|████████▋ | 60/69 [00:11<00:01,  5.09it/s, loss=52, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1:  87%|████████▋ | 60/69 [00:11<00:01,  5.09it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34mValidation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34mValidation:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:   0%|          | 0/9 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:rubout g m e f three nine\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  11%|█         | 1/9 [00:00<00:00, 15.29it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  88%|████████▊ | 61/69 [00:12<00:01,  5.00it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:j p e g four\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  22%|██▏       | 2/9 [00:00<00:00, 17.21it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  90%|████████▉ | 62/69 [00:12<00:01,  5.06it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:v a n e s s a\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  33%|███▎      | 3/9 [00:00<00:00, 18.70it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  91%|█████████▏| 63/69 [00:12<00:01,  5.13it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:p i t t s b u r g h\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  44%|████▍     | 4/9 [00:00<00:00, 18.15it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  93%|█████████▎| 64/69 [00:12<00:00,  5.18it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:march seven nineteen sixty seven\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  56%|█████▌    | 5/9 [00:00<00:00, 18.92it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  94%|█████████▍| 65/69 [00:12<00:00,  5.25it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:rubout c b w x v four\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  67%|██████▋   | 6/9 [00:00<00:00, 19.13it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  96%|█████████▌| 66/69 [00:12<00:00,  5.31it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:m y e r s\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  78%|███████▊  | 7/9 [00:00<00:00, 19.94it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  97%|█████████▋| 67/69 [00:12<00:00,  5.37it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:p h i n n e y\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0:  89%|████████▉ | 8/9 [00:00<00:00, 20.08it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1:  99%|█████████▊| 68/69 [00:12<00:00,  5.43it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1168]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1169] reference:four one two two six eight four one four two\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:26 wer:1170] predicted:\u001b[0m\n",
      "\u001b[34mValidation DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 21.27it/s]#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1: 100%|██████████| 69/69 [00:12<00:00,  5.50it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34mEpoch 1: 100%|██████████| 69/69 [00:12<00:00,  5.50it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mEpoch 1, global step 120: 'val_wer' reached 1.00000 (best 1.00000), saving model to '/opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1--val_wer=1.0000-epoch=1.ckpt' as top 5\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:27 exp_manager:972] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:27 exp_manager:972] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34mEpoch 1: 100%|██████████| 69/69 [00:13<00:00,  4.98it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m`Trainer.fit` stopped: `max_epochs=2` reached.\u001b[0m\n",
      "\u001b[34mEpoch 1: 100%|██████████| 69/69 [00:13<00:00,  4.98it/s, loss=54.1, v_num=0]\u001b[0m\n",
      "\u001b[34m[NeMo I 2023-03-22 10:59:28 exp_manager:972] New .nemo model saved to: /opt/ml/model/Conformer-CTC-Char1/checkpoints/Conformer-CTC-Char1.nemo\u001b[0m\n",
      "\u001b[34m2023-03-22 10:59:30,766 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-03-22 10:59:30,766 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-03-22 10:59:30,766 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-22 10:59:39 Uploading - Uploading generated training model\n",
      "2023-03-22 11:00:53 Completed - Training job completed\n",
      "Training seconds: 408\n",
      "Billable seconds: 408\n"
     ]
    }
   ],
   "source": [
    "if instance_type =='local_gpu': est.checkpoint_s3_uri = None\n",
    "\n",
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name)\n",
    "\n",
    "est.fit(\n",
    "    inputs=data_channels, \n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "      'TrialName': job_name,\n",
    "      'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014170a-2ee4-442b-a2f9-87b83d3c2b92",
   "metadata": {},
   "source": [
    "* save model-path, experiment-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16973040-93df-4afe-a9f9-ff95c811c94f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Store suceess'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.put_params(key=\"-\".join([prefix, \"MODEL-PATH\"]), value=est.model_data, overwrite=True)\n",
    "pm.put_params(key=\"-\".join([prefix, \"EXPERI-NAME\"]), value=experiment_name, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3eb52bf1-0562-43bb-a486-20f96ef3e555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nemo-asr-nemo-experiments-0322-10521679482352'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a9ce6-4677-4e70-a8b4-8765170d5a64",
   "metadata": {},
   "source": [
    "* show experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9b60a902-36d1-41e9-b0ba-f79fec992046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4b2cd44d-8a88-461a-8e5c-2328d1ec3621",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LocalSagemakerClient' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19546/2447556458.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m trial_component_training_analytics.dataframe()[['Experiments', 'Trials', \\\n\u001b[0m\u001b[1;32m     10\u001b[0m                                                 \u001b[0;34m'wer - Last'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wer - Min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wer - Max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wer - Avg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                 'train_loss - Last', 'train_loss - Min', 'train_loss - Max', 'train_loss - Avg']]\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sagemaker/analytics.py\u001b[0m in \u001b[0;36mdataframe\u001b[0;34m(self, force_refresh)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sagemaker/analytics.py\u001b[0m in \u001b[0;36m_fetch_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;34m\"\"\"Return a pandas dataframe includes all the trial_components.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trial_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sagemaker/analytics.py\u001b[0m in \u001b[0;36m_get_trial_components\u001b[0;34m(self, force_refresh)\u001b[0m\n\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_expression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_expression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sagemaker/analytics.py\u001b[0m in \u001b[0;36m_search\u001b[0;34m(self, search_expression, sort_by, sort_order)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_components\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_TRIAL_COMPONENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0msearch_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sage_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msearch_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrialComponent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mtrial_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LocalSagemakerClient' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "trial_component_training_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session= sagemaker_session,\n",
    "    experiment_name= experiment_name,\n",
    "    #sort_by=\"metrics.validation:auc.max\",        \n",
    "    #sort_order=\"Descending\",\n",
    "    #metric_names=[\"validation:auc\"]\n",
    ")\n",
    "\n",
    "trial_component_training_analytics.dataframe()[['Experiments', 'Trials', \\\n",
    "                                                'wer - Last', 'wer - Min', 'wer - Max', 'wer - Avg', \\\n",
    "                                                'train_loss - Last', 'train_loss - Min', 'train_loss - Max', 'train_loss - Avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83314c20-bd21-4da6-9751-1daee3b4a202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "df = TrainingJobAnalytics( training_job_name=job_name).dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07453386-2145-4516-b8f1-f3fe08c9b611",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>train_loss</td>\n",
       "      <td>76.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>wer</td>\n",
       "      <td>1170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp metric_name        value\n",
       "0        0.0  train_loss    76.866667\n",
       "1        0.0         wer  1170.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fa193-9ceb-4078-842f-c206b3a71224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5983e73-8957-466d-bc06-f214144a6903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9d2bd46-3533-4e92-919c-232bbc7acc6b",
   "metadata": {},
   "source": [
    "## code pipeline trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "553313b5-3afb-4dc4-ade8-5c1545dc0ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "pipeline_client = boto3.client('codepipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f5534-2270-414c-83aa-2e0cc73c09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "pipeline_client = boto3.client('codepipeline')\n",
    "code_pipeline_name = \"mlops-code-pipeline\"\n",
    "pipeline_client.start_pipeline_execution(name=code_pipeline_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
